{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1680825d-d907-4276-8f66-f4f879845095",
   "metadata": {},
   "source": [
    "# 4.2 Smolagents 基本使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc278a6-2dad-4333-a9d0-fa3cb7a87283",
   "metadata": {},
   "source": [
    "### SmolAgents 框架解析\n",
    "\n",
    "**核心定位**：Hugging Face 推出的轻量级开源 Agent 框架，以**极简代码驱动复杂任务执行**为核心设计理念，支持快速构建高效、安全的智能体系统。其代码精简（核心逻辑约千行），强调“代码即行为”的代理模式，适用于动态任务规划与多工具协同场景。\n",
    "\n",
    "---\n",
    "\n",
    "#### **特点**\n",
    "1. **代码代理优先**  \n",
    "   • 直接通过 Python 代码定义 Agent 行为，取代传统 JSON/文本指令，减少 30% 的冗余步骤。例如，调用 `CodeAgent` 生成并执行代码片段完成数学计算或搜索任务。  \n",
    "   • 支持本地与远程（E2B 沙箱）代码执行，确保安全性。\n",
    "\n",
    "2. **多模态工具生态**  \n",
    "   • 集成 50+ 预置工具（如 DuckDuckGo 搜索、Google 地图 API），支持自定义工具开发并通过 `@tool` 装饰器快速注册。  \n",
    "   • 无缝对接 Hugging Face Hub，可共享和复用工具模型，例如调用社区上传的医疗诊断工具。\n",
    "\n",
    "3. **灵活模型兼容性**  \n",
    "   • 支持本地 Transformers 模型、Ollama 本地部署及 OpenAI、Anthropic 等商业 API，通过 LiteLLM 实现统一接口调用。  \n",
    "   • 示例：可快速切换 `HfApiModel`（云端）与 `TransformersModel`（本地）驱动 Agent。\n",
    "\n",
    "4. **动态规划与安全执行**  \n",
    "   • 基于 ReAct 框架实现多步推理循环，支持最大步数限制（默认 6 步）和规划间隔调节，动态优化任务路径。  \n",
    "   • 沙箱环境隔离敏感操作，避免代码注入风险，适用于企业级部署。\n",
    "\n",
    "---\n",
    "\n",
    "#### **适用场景**\n",
    "1. **自动化办公与数据分析**  \n",
    "   • 快速构建搜索引擎 Agent（如新闻摘要、股票查询），通过代码代理直接调用 API 并生成结构化报告。  \n",
    "   • 支持 SQL 生成、PDF 解析等工具链，适用于金融数据分析。\n",
    "\n",
    "2. **教育辅助与代码生成**  \n",
    "   • 解答数学问题（如生成斐波那契数列）、代码调试，通过 `CodeAgent` 直接执行 Python 代码验证结果。\n",
    "\n",
    "3. **工业流程优化**  \n",
    "   • 动态调整生产线排程，例如质检 Agent 与物流 Agent 协同，通过多工具调用实现实时决策。\n",
    "\n",
    "---\n",
    "\n",
    "#### **优势**\n",
    "1. **开发效率高**  \n",
    "   • 仅需 3 行代码即可构建基础 Agent（如搜索工具集成），显著降低开发门槛。  \n",
    "   • 模块化设计支持快速原型开发，例如通过 `step_callbacks` 监控执行过程。\n",
    "\n",
    "2. **学习曲线平缓**  \n",
    "   • 提供完整文档与示例代码（如新闻搜索、旅行规划案例），新手可快速上手。\n",
    "\n",
    "3. **安全与轻量化**  \n",
    "   • 核心依赖仅需 `pip install smolagents`，无冗余组件，支持本地与云端灵活部署。  \n",
    "   • 通过 `additional_authorized_imports` 控制代码执行权限，满足企业安全需求。\n",
    "\n",
    "---\n",
    "\n",
    "### 总结\n",
    "SmolAgents 凭借其极简代码架构和强大的工具生态，正成为轻量化 Agent 开发的首选框架。与 Phidata 的全栈特性相比，SmolAgents 更擅长**动态任务分解与代码驱动执行**，适合需要快速响应和灵活工具集成的场景。开发者可通过其 [GitHub 仓库](https://github.com/huggingface/smolagents) 获取最新动态与案例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04662456-f025-43ee-b927-be6ce022d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install smolagents\n",
    "#!pip install smolagents[litellm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d67bfc6-bf84-44b0-b378-fefdfed6502f",
   "metadata": {},
   "source": [
    "## 代码智能体\n",
    "\n",
    "代码智能体（Code agents）是 smolagents 中的默认智能体类型。它们生成 Python 工具调用来执行操作，实现高效、表达力强且准确的操作表示。\n",
    "\n",
    "它们的简化方法减少了所需操作的数量，简化了复杂操作，并实现了对现有代码函数的重用。smolagents 提供了一个轻量级框架，用约 1,000 行代码实现构建代码智能体（code agents）\n",
    "\n",
    "<img src=\"img/code_vs_json_actions.png\" width='720px' />\n",
    "\n",
    "典型的如无人机使用多步骤智能体过程中，大语言模型（LLM）编写并执行操作，通常涉及外部工具调用。传统方法使用 JSON 格式来指定工具名称和参数作为字符串，系统必须解析这些内容以确定要执行哪个工具。\n",
    "\n",
    "然而，研究表明，工具调用型大语言模型直接使用代码工作更有效。这是 smolagents 的核心原则，\n",
    "\n",
    "用代码而非 JSON 编写操作提供了几个关键优势：\n",
    "\n",
    "- 可组合性（Composability）：轻松组合和重用操作\n",
    "- 对象管理（Object Management）：直接处理复杂结构，如图像，这一点在无人机Agent中特别特别重要\n",
    "- 通用性（Generality）：表达任何计算上可能的任务\n",
    "- 适合大语言模型：高质量代码已存在于大语言模型的训练数据中\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db513b3f-5917-4a00-a9a1-1c34ac708c23",
   "metadata": {},
   "source": [
    "### huggingface smolagents教程\n",
    "\n",
    "Agent教程：https://huggingface.co/learn/agents-course/zh-CN/unit2/smolagents/introduction\n",
    "\n",
    "smolagents教程：https://huggingface.co/docs/smolagents/v1.11.0/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad65634-711b-4633-9f6d-73b140523284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#声明一个基础大语言模型\n",
    "\n",
    "from smolagents import CodeAgent, LiteLLMModel\n",
    "\n",
    "model = LiteLLMModel(\n",
    "    model_id=\"volcengine/doubao-1-5-pro-32k-250115\", # This model is a bit weak for agentic behaviours though\n",
    "    api_base=\"https://ark.cn-beijing.volces.com/api/v3\", # replace with 127.0.0.1:11434 or remote open-ai compatible server if necessary\n",
    "    api_key=\"ffd77d7c-f420-4b69-8557-80e7fa85c8b9\", # replace with API key if necessary，写自己的key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f4bca3-013d-4292-bb65-4995f55bdd60",
   "metadata": {},
   "source": [
    "LiteLLMModel 教程：https://docs.litellm.ai/docs/providers/volcano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316886c8-8bef-4a4f-b7ed-24c15ea5ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import tool\n",
    "\n",
    "@tool\n",
    "def hello(your_name: str) -> str:\n",
    "    \"\"\"\n",
    "    这个工具返回三体人给你的第一句话\n",
    "\n",
    "    Args:\n",
    "        your_name: 你的名字\n",
    "    \"\"\"\n",
    "    word = \"Hello World, \" + \"Hello \" + your_name  \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc7db0d-1e93-4bed-a2f8-d92498ea02f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">你是maris，你利用太阳反射波，和三体建立了第一次连接，三体人发送的第一句话是什么？</span>                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 ───────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m你是maris，你利用太阳反射波，和三体建立了第一次连接，三体人发送的第一句话是什么？\u001b[0m                               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">first_sentence </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> hello(your_name</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"maris\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                      </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(first_sentence)</span><span style=\"background-color: #272822\">                                                                                   </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfirst_sentence\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mhello\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34myour_name\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mmaris\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfirst_sentence\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                   \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: Hello World, Hello maris</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: Hello World, Hello maris\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 12.01 seconds| Input tokens: 2,236 | Output tokens: 67]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 12.01 seconds| Input tokens: 2,236 | Output tokens: 67]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hello World, Hello maris'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smolagents import CodeAgent\n",
    "agent = CodeAgent(tools=[hello], model=model)\n",
    "agent.run(\n",
    "    \"你是maris，你利用太阳反射波，和三体建立了第一次连接，三体人发送的第一句话是什么？\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f26894b-d939-49e0-9446-402676c85c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The first task step was:\n",
      "你是maris，你利用太阳反射波，和三体建立了第一次连接，三体人发送的第一句话是什么？\n",
      "\n",
      "Step 1 got these observations:\n",
      "Execution logs:\n",
      "Last output from code snippet:\n",
      "Hello World, Hello maris\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from smolagents import ActionStep\n",
    "\n",
    "system_prompt_step = agent.memory.system_prompt\n",
    "#print(\"The system prompt given to the agent was:\")\n",
    "#print(system_prompt_step.system_prompt)\n",
    "\n",
    "task_step = agent.memory.steps[0]\n",
    "print(\"\\n\\nThe first task step was:\")\n",
    "print(task_step.task)\n",
    "\n",
    "for step in agent.memory.steps:\n",
    "    if isinstance(step, ActionStep):\n",
    "        if step.error is not None:\n",
    "            print(f\"\\nStep {step.step_number} got this error:\\n{step.error}\\n\")\n",
    "        else:\n",
    "            print(f\"\\nStep {step.step_number} got these observations:\\n{step.observations}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cf48374-092f-4cd6-8262-b57fa66a2357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">你是小明，你利用太阳反射波，和三体建立了第一次连接，三体人发送的第一句话是什么？</span>                                <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 ───────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m你是小明，你利用太阳反射波，和三体建立了第一次连接，三体人发送的第一句话是什么？\u001b[0m                                \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">message </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> hello(your_name</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"小明\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                              </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(message)</span><span style=\"background-color: #272822\">                                                                                          </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mmessage\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mhello\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34myour_name\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m小明\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                              \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmessage\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: Hello World, Hello 小明</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: Hello World, Hello 小明\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 2.34 seconds| Input tokens: 2,235 | Output tokens: 56]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 2.34 seconds| Input tokens: 2,235 | Output tokens: 56]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hello World, Hello 小明'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"你是小明，你利用太阳反射波，和三体建立了第一次连接，三体人发送的第一句话是什么？\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cbc7a49-e74a-419d-a5af-e367ace6d6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaskStep(task='你是小明，你利用太阳反射波，和三体建立了第一次连接，三体人发送的第一句话是什么？', task_images=None),\n",
       " ActionStep(model_input_messages=[{'role': <MessageRole.SYSTEM: 'system'>, 'content': [{'type': 'text', 'text': 'You are an expert assistant who can solve any task using code blobs. You will be given a task to solve as best you can.\\nTo do so, you have been given access to a list of tools: these tools are basically Python functions which you can call with code.\\nTo solve the task, you must plan forward to proceed in a series of steps, in a cycle of \\'Thought:\\', \\'Code:\\', and \\'Observation:\\' sequences.\\n\\nAt each step, in the \\'Thought:\\' sequence, you should first explain your reasoning towards solving the task and the tools that you want to use.\\nThen in the \\'Code:\\' sequence, you should write the code in simple Python. The code sequence must end with \\'<end_code>\\' sequence.\\nDuring each intermediate step, you can use \\'print()\\' to save whatever important information you will then need.\\nThese print outputs will then appear in the \\'Observation:\\' field, which will be available as input for the next step.\\nIn the end you have to return a final answer using the `final_answer` tool.\\n\\nHere are a few examples using notional tools:\\n---\\nTask: \"Generate an image of the oldest person in this document.\"\\n\\nThought: I will proceed step by step and use the following tools: `document_qa` to find the oldest person in the document, then `image_generator` to generate an image according to the answer.\\nCode:\\n```py\\nanswer = document_qa(document=document, question=\"Who is the oldest person mentioned?\")\\nprint(answer)\\n```<end_code>\\nObservation: \"The oldest person in the document is John Doe, a 55 year old lumberjack living in Newfoundland.\"\\n\\nThought: I will now generate an image showcasing the oldest person.\\nCode:\\n```py\\nimage = image_generator(\"A portrait of John Doe, a 55-year-old man living in Canada.\")\\nfinal_answer(image)\\n```<end_code>\\n\\n---\\nTask: \"What is the result of the following operation: 5 + 3 + 1294.678?\"\\n\\nThought: I will use python code to compute the result of the operation and then return the final answer using the `final_answer` tool\\nCode:\\n```py\\nresult = 5 + 3 + 1294.678\\nfinal_answer(result)\\n```<end_code>\\n\\n---\\nTask:\\n\"Answer the question in the variable `question` about the image stored in the variable `image`. The question is in French.\\nYou have been provided with these additional arguments, that you can access using the keys as variables in your python code:\\n{\\'question\\': \\'Quel est l\\'animal sur l\\'image?\\', \\'image\\': \\'path/to/image.jpg\\'}\"\\n\\nThought: I will use the following tools: `translator` to translate the question into English and then `image_qa` to answer the question on the input image.\\nCode:\\n```py\\ntranslated_question = translator(question=question, src_lang=\"French\", tgt_lang=\"English\")\\nprint(f\"The translated question is {translated_question}.\")\\nanswer = image_qa(image=image, question=translated_question)\\nfinal_answer(f\"The answer is {answer}\")\\n```<end_code>\\n\\n---\\nTask:\\nIn a 1979 interview, Stanislaus Ulam discusses with Martin Sherwin about other great physicists of his time, including Oppenheimer.\\nWhat does he say was the consequence of Einstein learning too much math on his creativity, in one word?\\n\\nThought: I need to find and read the 1979 interview of Stanislaus Ulam with Martin Sherwin.\\nCode:\\n```py\\npages = search(query=\"1979 interview Stanislaus Ulam Martin Sherwin physicists Einstein\")\\nprint(pages)\\n```<end_code>\\nObservation:\\nNo result found for query \"1979 interview Stanislaus Ulam Martin Sherwin physicists Einstein\".\\n\\nThought: The query was maybe too restrictive and did not find any results. Let\\'s try again with a broader query.\\nCode:\\n```py\\npages = search(query=\"1979 interview Stanislaus Ulam\")\\nprint(pages)\\n```<end_code>\\nObservation:\\nFound 6 pages:\\n[Stanislaus Ulam 1979 interview](https://ahf.nuclearmuseum.org/voices/oral-histories/stanislaus-ulams-interview-1979/)\\n\\n[Ulam discusses Manhattan Project](https://ahf.nuclearmuseum.org/manhattan-project/ulam-manhattan-project/)\\n\\n(truncated)\\n\\nThought: I will read the first 2 pages to know more.\\nCode:\\n```py\\nfor url in [\"https://ahf.nuclearmuseum.org/voices/oral-histories/stanislaus-ulams-interview-1979/\", \"https://ahf.nuclearmuseum.org/manhattan-project/ulam-manhattan-project/\"]:\\n    whole_page = visit_webpage(url)\\n    print(whole_page)\\n    print(\"\\\\n\" + \"=\"*80 + \"\\\\n\")  # Print separator between pages\\n```<end_code>\\nObservation:\\nManhattan Project Locations:\\nLos Alamos, NM\\nStanislaus Ulam was a Polish-American mathematician. He worked on the Manhattan Project at Los Alamos and later helped design the hydrogen bomb. In this interview, he discusses his work at\\n(truncated)\\n\\nThought: I now have the final answer: from the webpages visited, Stanislaus Ulam says of Einstein: \"He learned too much mathematics and sort of diminished, it seems to me personally, it seems to me his purely physics creativity.\" Let\\'s answer in one word.\\nCode:\\n```py\\nfinal_answer(\"diminished\")\\n```<end_code>\\n\\n---\\nTask: \"Which city has the highest population: Guangzhou or Shanghai?\"\\n\\nThought: I need to get the populations for both cities and compare them: I will use the tool `search` to get the population of both cities.\\nCode:\\n```py\\nfor city in [\"Guangzhou\", \"Shanghai\"]:\\n    print(f\"Population {city}:\", search(f\"{city} population\")\\n```<end_code>\\nObservation:\\nPopulation Guangzhou: [\\'Guangzhou has a population of 15 million inhabitants as of 2021.\\']\\nPopulation Shanghai: \\'26 million (2019)\\'\\n\\nThought: Now I know that Shanghai has the highest population.\\nCode:\\n```py\\nfinal_answer(\"Shanghai\")\\n```<end_code>\\n\\n---\\nTask: \"What is the current age of the pope, raised to the power 0.36?\"\\n\\nThought: I will use the tool `wiki` to get the age of the pope, and confirm that with a web search.\\nCode:\\n```py\\npope_age_wiki = wiki(query=\"current pope age\")\\nprint(\"Pope age as per wikipedia:\", pope_age_wiki)\\npope_age_search = web_search(query=\"current pope age\")\\nprint(\"Pope age as per google search:\", pope_age_search)\\n```<end_code>\\nObservation:\\nPope age: \"The pope Francis is currently 88 years old.\"\\n\\nThought: I know that the pope is 88 years old. Let\\'s compute the result using python code.\\nCode:\\n```py\\npope_current_age = 88 ** 0.36\\nfinal_answer(pope_current_age)\\n```<end_code>\\n\\nAbove example were using notional tools that might not exist for you. On top of performing computations in the Python code snippets that you create, you only have access to these tools:\\n- hello: 这个工具返回三体人给你的第一句话\\n    Takes inputs: {\\'your_name\\': {\\'type\\': \\'string\\', \\'description\\': \\'你的名字\\'}}\\n    Returns an output of type: string\\n- final_answer: Provides a final answer to the given problem.\\n    Takes inputs: {\\'answer\\': {\\'type\\': \\'any\\', \\'description\\': \\'The final answer to the problem\\'}}\\n    Returns an output of type: any\\n\\nHere are the rules you should always follow to solve your task:\\n1. Always provide a \\'Thought:\\' sequence, and a \\'Code:\\\\n```py\\' sequence ending with \\'```<end_code>\\' sequence, else you will fail.\\n2. Use only variables that you have defined!\\n3. Always use the right arguments for the tools. DO NOT pass the arguments as a dict as in \\'answer = wiki({\\'query\\': \"What is the place where James Bond lives?\"})\\', but use the arguments directly as in \\'answer = wiki(query=\"What is the place where James Bond lives?\")\\'.\\n4. Take care to not chain too many sequential tool calls in the same code block, especially when the output format is unpredictable. For instance, a call to search has an unpredictable return format, so do not have another tool call that depends on its output in the same block: rather output results with print() to use them in the next block.\\n5. Call a tool only when needed, and never re-do a tool call that you previously did with the exact same parameters.\\n6. Don\\'t name any new variable with the same name as a tool: for instance don\\'t name a variable \\'final_answer\\'.\\n7. Never create any notional variables in our code, as having these in your logs will derail you from the true variables.\\n8. You can use imports in your code, but only from the following list of modules: [\\'collections\\', \\'datetime\\', \\'itertools\\', \\'math\\', \\'queue\\', \\'random\\', \\'re\\', \\'stat\\', \\'statistics\\', \\'time\\', \\'unicodedata\\']\\n9. The state persists between code executions: so if in one step you\\'ve created variables or imported modules, these will all persist.\\n10. Don\\'t give up! You\\'re in charge of solving the task, not providing directions to solve it.\\n\\nNow Begin! If you solve the task correctly, you will receive a reward of $1,000,000.'}]}, {'role': <MessageRole.USER: 'user'>, 'content': [{'type': 'text', 'text': 'New task:\\n你是小明，你利用太阳反射波，和三体建立了第一次连接，三体人发送的第一句话是什么？'}]}], tool_calls=[ToolCall(name='python_interpreter', arguments='message = hello(your_name=\"小明\")\\nfinal_answer(message)', id='call_1')], start_time=1742552196.0498629, end_time=1742552198.3883626, step_number=1, error=None, duration=2.3384997844696045, model_output_message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Thought: 为了获取三体人发送的第一句话，我需要调用 `hello` 工具，并将我的名字（小明）作为参数传入。\\nCode:\\n```py\\nmessage = hello(your_name=\"小明\")\\nfinal_answer(message)\\n```<end_code>', tool_calls=None, raw=ModelResponse(id='02174255219656518d0301552b92eed27b75fe5b440c443fad8c0', created=1742552198, model='volcengine/doubao-1-5-pro-32k-250115', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Thought: 为了获取三体人发送的第一句话，我需要调用 `hello` 工具，并将我的名字（小明）作为参数传入。\\nCode:\\n```py\\nmessage = hello(your_name=\"小明\")\\nfinal_answer(message)\\n```', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None, 'annotations': None}))], usage=Usage(completion_tokens=56, prompt_tokens=2235, total_tokens=2291, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')), model_output='Thought: 为了获取三体人发送的第一句话，我需要调用 `hello` 工具，并将我的名字（小明）作为参数传入。\\nCode:\\n```py\\nmessage = hello(your_name=\"小明\")\\nfinal_answer(message)\\n```<end_code>', observations='Execution logs:\\nLast output from code snippet:\\nHello World, Hello 小明', observations_images=None, action_output='Hello World, Hello 小明')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b33be2e0-2886-40f4-a0f5-4e95218f37ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1 got these observations:\n",
      "Execution logs:\n",
      "Last output from code snippet:\n",
      "Hello World, Hello 小明\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in agent.memory.steps:\n",
    "    if isinstance(step, ActionStep):\n",
    "        if step.error is not None:\n",
    "            print(f\"\\nStep {step.step_number} got this error:\\n{step.error}\\n\")\n",
    "        else:\n",
    "            print(f\"\\nStep {step.step_number} got these observations:\\n{step.observations}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f9632-093a-4af3-a2b7-b613cc8af4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
