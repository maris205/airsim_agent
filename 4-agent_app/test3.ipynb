{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8fe0e27-c2bb-4e1d-a017-4f5cf720d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install smolagents[litellm]\n",
    "from smolagents import CodeAgent, LiteLLMModel\n",
    "\n",
    "model = LiteLLMModel(\n",
    "    model_id=\"volcengine/doubao-1-5-pro-32k-250115\", # This model is a bit weak for agentic behaviours though\n",
    "    api_base=\"https://ark.cn-beijing.volces.com/api/v3\", # replace with 127.0.0.1:11434 or remote open-ai compatible server if necessary\n",
    "    api_key=\"058a54a8-25d4-4157-81c7-1c54d50fe0d8\", # replace with API key if necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c9e7c-7e74-43cc-b762-6954392b8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(tools=[], model=model, add_base_tools=True)\n",
    "\n",
    "agent.run(\n",
    "    \"Could you give me the 118th number in the Fibonacci sequence?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57da086c-6b5e-43ae-be2d-95c4b2892da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = CodeAgent(tools=[], model=model, additional_authorized_imports=['requests', 'bs4'])\n",
    "# agent.run(\"Could you get me the title of the page at url 'https://huggingface.co/blog'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d79daa71-293f-4a7c-864a-97fad6106748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from smolagents import ToolCallingAgent\n",
    "\n",
    "# agent = ToolCallingAgent(tools=[], model=model)\n",
    "# agent.run(\"Could you get me the title of the page at url 'https://www.baidu.com'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed2ee53-79b3-48c9-aaf2-d18a4c1e177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Search Results\n",
      "\n",
      "[Vladimir Putin - Wikipedia](https://en.wikipedia.org/wiki/Vladimir_Putin)\n",
      "Vladimir Vladimirovich Putin[c][d] (born 7 October 1952) is a Russian politician and former intelligence officer who has served as President of Russia since 2012, having previously served from 2000 to 2008. Putin also served as Prime Minister of Russia from 1999 to 2000 [e] and again from 2008 to 2012. [f][7] He is the longest-serving Russian president since the independence of Russia from the ...\n",
      "\n",
      "[Presidents of Russia ∙ President ∙ Structure ... - President of Russia](http://www.en.kremlin.ru/structure/president/presidents)\n",
      "2004 On March 14, 2004, he was elected President of Russia for the second term. 2008 Since May 8, 2008, Vladimir Putin is a Prime Minister of Russia. 2012 On March 4, 2012, he was elected President of Russia and inaugurated on May 7, 2012. 2018 On March 18, 2018, he was re-elected President of Russia. Assumed office on May 7, 2018. 2024\n",
      "\n",
      "[Vladimir Putin | Biography, KGB, Political Career, & Facts | Britannica](https://www.britannica.com/biography/Vladimir-Putin)\n",
      "Vladimir Putin is a Russian leader and former KGB officer who has shaped his nation's political landscape for decades with a mix of strategic maneuvers, military aggression against Russia's neighbors, and controversial policies.\n",
      "\n",
      "[President of Russia](http://en.kremlin.ru/)\n",
      "President's website resources President of Russia Current resource The Constitution of Russia State Insignia Send a Letter Vladimir Putin's Personal Website\n",
      "\n",
      "[Presidents Of Russia Since The Fall Of The Soviet Union](https://www.worldatlas.com/articles/presidents-of-russia-since-the-fall-of-the-soviet-union.html)\n",
      "Russia has a semi-presidential government where the president and the prime minister share governing responsibility. The current president of Russia is Vladimir Putin.\n",
      "\n",
      "[President ∙ Structure ∙ President of Russia](http://en.kremlin.ru/structure/president)\n",
      "The President of the Russian Federation is the head of state and guarantor of the Constitution and of human and civil rights and freedoms. The President is elected for a 6-year term by the Russian Federation's citizens on the basis of universal, equal and direct suffrage by secret ballot.\n",
      "\n",
      "[Putin inaugurated as president for fifth term with Russia under tight ...](https://www.cnn.com/2024/05/07/europe/putin-inauguration-russia-president-fifth-term-intl/index.html)\n",
      "Vladimir Putin has formally begun his fifth term as Russia's president in a carefully choreographed inauguration ceremony, in a country he has shaped in his image after first taking office ...\n",
      "\n",
      "[President of Russia - Президент России](http://www.en.special.kremlin.ru/structure/president)\n",
      "The President of the Russian Federation is the head of state and guarantor of the Constitution and of human and civil rights and freedoms. The President is elected for a 6-year term by the Russian Federation's citizens on the basis of universal, equal and direct suffrage by secret ballot.\n",
      "\n",
      "[President of Russia - Simple English Wikipedia, the free encyclopedia](https://simple.wikipedia.org/wiki/President_of_Russia)\n",
      "The current president is Vladimir Putin. Boris Yeltsin was the first president of Russia, Vladimir Putin was second and fourth, and Dmitry Medvedev was the third. The President's duties are listed in the 1993 Russian Constitution. The president directs the foreign and domestic policy of the Russian Federation.\n",
      "\n",
      "[Putin secures 5th term as Russia's president after preordained ... - PBS](https://www.pbs.org/newshour/world/putin-secures-5th-term-as-russias-president-after-preordained-election)\n",
      "Putin has led Russia as president or prime minister since December 1999, a tenure marked by international military aggression and an increasing intolerance for dissent.\n"
     ]
    }
   ],
   "source": [
    "from smolagents import DuckDuckGoSearchTool\n",
    "\n",
    "search_tool = DuckDuckGoSearchTool()\n",
    "print(search_tool(\"Who's the current president of Russia?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d2facb6-ef7d-464d-ba2a-ac2b6f0e3a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-encoder/ms-marco-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_models\n",
    "\n",
    "task = \"text-classification\"\n",
    "\n",
    "most_downloaded_model = next(iter(list_models(filter=task, sort=\"downloads\", direction=-1)))\n",
    "print(most_downloaded_model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4b99a65-c526-4449-b1b3-fcf3f0e954b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import tool\n",
    "\n",
    "@tool\n",
    "def model_download_tool(task: str) -> str:\n",
    "    \"\"\"\n",
    "    This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub.\n",
    "    It returns the name of the checkpoint.\n",
    "\n",
    "    Args:\n",
    "        task: The task for which to get the download count.\n",
    "    \"\"\"\n",
    "    most_downloaded_model = next(iter(list_models(filter=task, sort=\"downloads\", direction=-1)))\n",
    "    return most_downloaded_model.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd5d8fe1-1a95-43fb-9f24-e19600c7c7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Can you give me the name of the model that has the most downloads in the 'text-to-video' task on the Hugging </span>   <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Face Hub?</span>                                                                                                       <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 ───────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mCan you give me the name of the model that has the most downloads in the 'text-to-video' task on the Hugging \u001b[0m   \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mFace Hub?\u001b[0m                                                                                                       \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">model_name </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> model_download_tool(task</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"text-to-video\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                         </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(model_name)</span><span style=\"background-color: #272822\">                                                                                       </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mmodel_name\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel_download_tool\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtask\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtext-to-video\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel_name\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: Wan-AI/Wan2.1-T2V-14B</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: Wan-AI/Wan2.1-T2V-14B\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 4.26 seconds| Input tokens: 2,268 | Output tokens: 64]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 4.26 seconds| Input tokens: 2,268 | Output tokens: 64]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Wan-AI/Wan2.1-T2V-14B'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smolagents import CodeAgent, HfApiModel\n",
    "agent = CodeAgent(tools=[model_download_tool], model=model)\n",
    "agent.run(\n",
    "    \"Can you give me the name of the model that has the most downloads in the 'text-to-video' task on the Hugging Face Hub?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ea19096-41d2-48aa-8429-256f1b999576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import Tool\n",
    "\n",
    "class ModelDownloadTool(Tool):\n",
    "    name = \"model_download_tool\"\n",
    "    description = \"This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub. It returns the name of the checkpoint.\"\n",
    "    inputs = {\"task\": {\"type\": \"string\", \"description\": \"The task for which to get the download count.\"}}\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def forward(self, task: str) -> str:\n",
    "        most_downloaded_model = next(iter(list_models(filter=task, sort=\"downloads\", direction=-1)))\n",
    "        return most_downloaded_model.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5eb5b967-1512-4f1f-a3a3-895b633c177b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Can you give me the name of the model that has the most downloads in the 'text-to-video' task on the Hugging </span>   <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Face Hub?</span>                                                                                                       <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 ───────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mCan you give me the name of the model that has the most downloads in the 'text-to-video' task on the Hugging \u001b[0m   \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mFace Hub?\u001b[0m                                                                                                       \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">model_name </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> model_download_tool(task</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"text-to-video\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                         </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(model_name)</span><span style=\"background-color: #272822\">                                                                                       </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mmodel_name\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel_download_tool\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtask\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtext-to-video\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel_name\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: Wan-AI/Wan2.1-T2V-14B</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: Wan-AI/Wan2.1-T2V-14B\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 3.71 seconds| Input tokens: 2,268 | Output tokens: 64]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 3.71 seconds| Input tokens: 2,268 | Output tokens: 64]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Wan-AI/Wan2.1-T2V-14B'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smolagents import CodeAgent, HfApiModel\n",
    "agent = CodeAgent(tools=[model_download_tool], model=model)\n",
    "agent.run(\n",
    "    \"Can you give me the name of the model that has the most downloads in the 'text-to-video' task on the Hugging Face Hub?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f32d63ae-295a-4bf8-bca8-6c510ea0b174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Who is the CEO of Hugging Face?</span>                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 ───────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mWho is the CEO of Hugging Face?\u001b[0m                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">ceo_info </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> web_search_duck(task</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Find out who is the CEO of Hugging Face.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                    </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(ceo_info)</span><span style=\"background-color: #272822\">                                                                                                </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mceo_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mweb_search_duck\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtask\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mFind out who is the CEO of Hugging Face.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                    \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mceo_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭─────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run - web_search_duck</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ───────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">You're a helpful agent named 'web_search_duck'.</span>                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">You have been submitted this task by your manager.</span>                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">---</span>                                                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Task:</span>                                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Find out who is the CEO of Hugging Face.</span>                                                                        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">---</span>                                                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">You're helping your manager solve a wider task: so make sure to not provide a one-line answer, but give as much</span> <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">information as possible to give them a clear understanding of the answer.</span>                                       <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Your final_answer WILL HAVE to contain these parts:</span>                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">### 1. Task outcome (short version):</span>                                                                            <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">### 2. Task outcome (extremely detailed version):</span>                                                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">### 3. Additional context (if relevant):</span>                                                                        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Put all these in your final_answer tool, everything that you do not pass as an argument to final_answer will be</span> <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">lost.</span>                                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">And even if your task resolution is not successful, please return as much context as possible, so that your </span>    <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">manager can act upon this feedback.</span>                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 ───────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run - web_search_duck\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYou're a helpful agent named 'web_search_duck'.\u001b[0m                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYou have been submitted this task by your manager.\u001b[0m                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m---\u001b[0m                                                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mTask:\u001b[0m                                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mFind out who is the CEO of Hugging Face.\u001b[0m                                                                        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m---\u001b[0m                                                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYou're helping your manager solve a wider task: so make sure to not provide a one-line answer, but give as much\u001b[0m \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1minformation as possible to give them a clear understanding of the answer.\u001b[0m                                       \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYour final_answer WILL HAVE to contain these parts:\u001b[0m                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m### 1. Task outcome (short version):\u001b[0m                                                                            \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m### 2. Task outcome (extremely detailed version):\u001b[0m                                                               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m### 3. Additional context (if relevant):\u001b[0m                                                                        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mPut all these in your final_answer tool, everything that you do not pass as an argument to final_answer will be\u001b[0m \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mlost.\u001b[0m                                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mAnd even if your task resolution is not successful, please return as much context as possible, so that your \u001b[0m    \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mmanager can act upon this feedback.\u001b[0m                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - volcengine/doubao-1-5-pro-32k-250115 \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">ceo_info </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> web_search(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Who is the CEO of Hugging Face?\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                 </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(ceo_info)</span><span style=\"background-color: #272822\">                                                                                                </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mceo_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mweb_search\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mWho is the CEO of Hugging Face?\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                 \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mceo_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "## Search Results\n",
       "\n",
       "[Hugging Face - Wikipedia](https://en.wikipedia.org/wiki/Hugging_Face)\n",
       "Hugging Face, Inc. is an American company incorporated under the Delaware General Corporation Law [1] and based in \n",
       "New York City that develops computation tools for building applications using machine learning.It is most notable \n",
       "for its transformers library built for natural language processing applications and its platform that allows users \n",
       "to share machine learning models and datasets and ...\n",
       "\n",
       "[Who is the CEO of Hugging Face? Clem Delangue 's Bio - Clay](https://www.clay.com/dossier/hugging-face-ceo)\n",
       "Clément Delangue is the CEO and co-founder of Hugging Face, an open and collaborative platform for AI builders. \n",
       "With a background in entrepreneurship and education from Stanford University, Delangue has played a pivotal role in\n",
       "growing Hugging Face into a leading AI platform valued at $4.5 billion, hosting over a million open-source \n",
       "repositories and serving more than 15,000 companies ...\n",
       "\n",
       "[Clem Delangue - Hugging Face - LinkedIn](https://www.linkedin.com/in/clementdelangue)\n",
       "· Hugging Face · Miami-Fort Lauderdale Area · 500+ connections on LinkedIn. View Clem Delangue 🤗's profile on \n",
       "LinkedIn, a professional community of 1 billion members. ... Co-founder &amp; CEO ...\n",
       "\n",
       "[List of Hugging Face Executives &amp; Org Chart | Clay](https://www.clay.com/dossier/hugging-face-executives)\n",
       "At the top of Hugging Face's organizational chart is Clement Delangue, the Co-Founder and CEO, who oversees the \n",
       "company's overall vision and strategic direction. Directly reporting to him are Julien Chaumond, the Co-Founder and\n",
       "CTO, and Thomas Wolf, the Co-Founder and Chief Science Officer, both of whom play crucial roles in driving ...\n",
       "\n",
       "[Clément Delangue, CEO of Hugging Face, built the GitHub of \n",
       "AI](https://www.fastcompany.com/90909717/clement-delangue-ceo-hugging-face-most-creative-people-2023)\n",
       "The gathering was a real-world manifestation of the community Delangue has created as CEO of Hugging Face. Founded \n",
       "in 2016 and based in Brooklyn, the company had originally built a chatbot aimed ...\n",
       "\n",
       "[Meet Hugging Face CEO Clement Delangue | \n",
       "ICT-Mirror](https://ictmirror.com/entertainment/hugging-face-ceo-clement-delangue/)\n",
       "Entrepreneurial Journey Of The Hugging Face CEO Clement Delangue. Clement Delangue is the CEO and co-founder of \n",
       "Hugging Face. He is a native of quaint town of La Bassee in northern France.. Growing up in an ordinary household, \n",
       "Clem's interest in technology was piqued when he got his first computer at the age of 12.\n",
       "\n",
       "[The Inspiring Journey of Clément Delangue, Hugging Face's \n",
       "founder](https://kitrum.com/blog/the-inspiring-journey-of-clement-delangue-hugging-faces-founder/)\n",
       "Prepare yourself for an interesting journey where we're going to talk about the inspirational success story of the \n",
       "CEO and co-founder of Hugging Face, a startup that develops artificial intelligence software and provides hosting \n",
       "services for other businesses valued at $4.5 billion - Clement Delaunge. We will speak about his background, the \n",
       "...\n",
       "\n",
       "[Hugging Face CEO And Leadership: Executives and \n",
       "Demographics](https://www.zippia.com/hugging-face-careers-1414309/executives/)\n",
       "Executive Summary. Based on our data team's research, Clement Delangue is the Hugging Face's CEO. Hugging Face has \n",
       "30 employees, of which 6 are in a leadership position.\n",
       "\n",
       "[The $2 Billion Emoji: Hugging Face Wants To Be Launchpad For A ... - \n",
       "Forbes](https://www.forbes.com/sites/kenrickcai/2022/05/09/the-2-billion-emoji-hugging-face-wants-to-be-launchpad-f\n",
       "or-a-machine-learning-revolution/)\n",
       "Hugging Face CEO Clément Delangue. Growing up in La Bassée, a small town of 6,000 in the north of France, Delangue \n",
       "recalls an idle childhood until he got his first computer at age 12. By 17, he ...\n",
       "\n",
       "[Hugging Face Business Model: How It Makes Money (2025) - \n",
       "productmint](https://productmint.com/hugging-face-business-model/)\n",
       "Hugging Face, headquartered in New York City, was founded in 2016 by Clement Delangue, Julien Chaumond, and Thomas \n",
       "Wolf. Delangue, Hugging Face's CEO, grew up in a small town north of France where there wasn't much to do besides \n",
       "being on his computer, which he was gifted at the age of 12.\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "## Search Results\n",
       "\n",
       "[Hugging Face - Wikipedia](https://en.wikipedia.org/wiki/Hugging_Face)\n",
       "Hugging Face, Inc. is an American company incorporated under the Delaware General Corporation Law [1] and based in \n",
       "New York City that develops computation tools for building applications using machine learning.It is most notable \n",
       "for its transformers library built for natural language processing applications and its platform that allows users \n",
       "to share machine learning models and datasets and ...\n",
       "\n",
       "[Who is the CEO of Hugging Face? Clem Delangue 's Bio - Clay](https://www.clay.com/dossier/hugging-face-ceo)\n",
       "Clément Delangue is the CEO and co-founder of Hugging Face, an open and collaborative platform for AI builders. \n",
       "With a background in entrepreneurship and education from Stanford University, Delangue has played a pivotal role in\n",
       "growing Hugging Face into a leading AI platform valued at $4.5 billion, hosting over a million open-source \n",
       "repositories and serving more than 15,000 companies ...\n",
       "\n",
       "[Clem Delangue - Hugging Face - LinkedIn](https://www.linkedin.com/in/clementdelangue)\n",
       "· Hugging Face · Miami-Fort Lauderdale Area · 500+ connections on LinkedIn. View Clem Delangue 🤗's profile on \n",
       "LinkedIn, a professional community of 1 billion members. ... Co-founder & CEO ...\n",
       "\n",
       "[List of Hugging Face Executives & Org Chart | Clay](https://www.clay.com/dossier/hugging-face-executives)\n",
       "At the top of Hugging Face's organizational chart is Clement Delangue, the Co-Founder and CEO, who oversees the \n",
       "company's overall vision and strategic direction. Directly reporting to him are Julien Chaumond, the Co-Founder and\n",
       "CTO, and Thomas Wolf, the Co-Founder and Chief Science Officer, both of whom play crucial roles in driving ...\n",
       "\n",
       "[Clément Delangue, CEO of Hugging Face, built the GitHub of \n",
       "AI](https://www.fastcompany.com/90909717/clement-delangue-ceo-hugging-face-most-creative-people-2023)\n",
       "The gathering was a real-world manifestation of the community Delangue has created as CEO of Hugging Face. Founded \n",
       "in 2016 and based in Brooklyn, the company had originally built a chatbot aimed ...\n",
       "\n",
       "[Meet Hugging Face CEO Clement Delangue | \n",
       "ICT-Mirror](https://ictmirror.com/entertainment/hugging-face-ceo-clement-delangue/)\n",
       "Entrepreneurial Journey Of The Hugging Face CEO Clement Delangue. Clement Delangue is the CEO and co-founder of \n",
       "Hugging Face. He is a native of quaint town of La Bassee in northern France.. Growing up in an ordinary household, \n",
       "Clem's interest in technology was piqued when he got his first computer at the age of 12.\n",
       "\n",
       "[The Inspiring Journey of Clément Delangue, Hugging Face's \n",
       "founder](https://kitrum.com/blog/the-inspiring-journey-of-clement-delangue-hugging-faces-founder/)\n",
       "Prepare yourself for an interesting journey where we're going to talk about the inspirational success story of the \n",
       "CEO and co-founder of Hugging Face, a startup that develops artificial intelligence software and provides hosting \n",
       "services for other businesses valued at $4.5 billion - Clement Delaunge. We will speak about his background, the \n",
       "...\n",
       "\n",
       "[Hugging Face CEO And Leadership: Executives and \n",
       "Demographics](https://www.zippia.com/hugging-face-careers-1414309/executives/)\n",
       "Executive Summary. Based on our data team's research, Clement Delangue is the Hugging Face's CEO. Hugging Face has \n",
       "30 employees, of which 6 are in a leadership position.\n",
       "\n",
       "[The $2 Billion Emoji: Hugging Face Wants To Be Launchpad For A ... - \n",
       "Forbes](https://www.forbes.com/sites/kenrickcai/2022/05/09/the-2-billion-emoji-hugging-face-wants-to-be-launchpad-f\n",
       "or-a-machine-learning-revolution/)\n",
       "Hugging Face CEO Clément Delangue. Growing up in La Bassée, a small town of 6,000 in the north of France, Delangue \n",
       "recalls an idle childhood until he got his first computer at age 12. By 17, he ...\n",
       "\n",
       "[Hugging Face Business Model: How It Makes Money (2025) - \n",
       "productmint](https://productmint.com/hugging-face-business-model/)\n",
       "Hugging Face, headquartered in New York City, was founded in 2016 by Clement Delangue, Julien Chaumond, and Thomas \n",
       "Wolf. Delangue, Hugging Face's CEO, grew up in a small town north of France where there wasn't much to do besides \n",
       "being on his computer, which he was gifted at the age of 12.\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 3.21 seconds| Input tokens: 2,416 | Output tokens: 57]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 3.21 seconds| Input tokens: 2,416 | Output tokens: 57]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating model output:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">litellm.BadRequestError: VolcengineException - The parameter `messages.content` specified in the request are not </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">valid: expected a string, but got `[{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">,</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Thought: I will use the `web_search` tool to find out </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">who is the CEO of Hugging Face.\\nCode:\\n```py\\nceo_info = web_search(query=\\\"Who is the CEO of Hugging </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Face?\\\")\\nprint(ceo_info)\\n```&lt;end_code&gt;\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">},{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">,</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Calling tools:\\n[{'id': 'call_1', 'type': </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'function', 'function': {'name': 'python_interpreter', 'arguments': 'ceo_info = web_search(query=\\\"Who is the CEO </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of Hugging Face?\\\")\\\\nprint(ceo_info)'}}\\]\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">}]` instead. Request id: </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">021742525541723d90807d1791e3f67b1750870f5bd8bf7225952</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in generating model output:\u001b[0m\n",
       "\u001b[1;31mlitellm.BadRequestError: VolcengineException - The parameter `messages.content` specified in the request are not \u001b[0m\n",
       "\u001b[1;31mvalid: expected a string, but got `\u001b[0m\u001b[1;31m[\u001b[0m\u001b[1;31m{\u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m,\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"Thought: I will use the `web_search` tool to find out \u001b[0m\n",
       "\u001b[32mwho is the CEO of Hugging Face.\\nCode:\\n```py\\nceo_info = web_search\u001b[0m\u001b[32m(\u001b[0m\u001b[32mquery\u001b[0m\u001b[32m=\\\"Who is the CEO of Hugging \u001b[0m\n",
       "\u001b[32mFace?\\\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nprint\u001b[0m\u001b[32m(\u001b[0m\u001b[32mceo_info\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\u001b[0m\u001b[32m<\u001b[0m\u001b[32mend_code\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\"\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m,\u001b[0m\u001b[1;31m{\u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m,\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"Calling tools:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m'id': 'call_1', 'type': \u001b[0m\n",
       "\u001b[32m'function', 'function': \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'name': 'python_interpreter', 'arguments': 'ceo_info = web_search\u001b[0m\u001b[32m(\u001b[0m\u001b[32mquery\u001b[0m\u001b[32m=\\\"Who is the CEO \u001b[0m\n",
       "\u001b[32mof Hugging Face?\\\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\nprint\u001b[0m\u001b[32m(\u001b[0m\u001b[32mceo_info\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m]\u001b[0m\u001b[1;31m` instead. Request id: \u001b[0m\n",
       "\u001b[1;31m021742525541723d90807d1791e3f67b1750870f5bd8bf7225952\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 0.07 seconds| Input tokens: 4,832 | Output tokens: 114]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 0.07 seconds| Input tokens: 4,832 | Output tokens: 114]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Code execution failed at line </span><span style=\"color: #008000; text-decoration-color: #008000\">'ceo_info = web_search_duck(task=\"Find out who is the CEO of Hugging Face.\")'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> due to:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">AgentGenerationError: Error in generating model output:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">litellm.BadRequestError: VolcengineException - The parameter `messages.content` specified in the request are not </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">valid: expected a string, but got `[{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">,</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Thought: I will use the `web_search` tool to find out </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">who is the CEO of Hugging Face.\\nCode:\\n```py\\nceo_info = web_search(query=\\\"Who is the CEO of Hugging </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Face?\\\")\\nprint(ceo_info)\\n```&lt;end_code&gt;\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">},{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">,</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Calling tools:\\n[{'id': 'call_1', 'type': </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'function', 'function': {'name': 'python_interpreter', 'arguments': 'ceo_info = web_search(query=\\\"Who is the CEO </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of Hugging Face?\\\")\\\\nprint(ceo_info)'}}\\]\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">}]` instead. Request id: </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">021742525541723d90807d1791e3f67b1750870f5bd8bf7225952</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mCode execution failed at line \u001b[0m\u001b[32m'ceo_info = web_search_duck\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtask\u001b[0m\u001b[32m=\u001b[0m\u001b[32m\"Find\u001b[0m\u001b[32m out who is the CEO of Hugging Face.\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;31m due to:\u001b[0m\n",
       "\u001b[1;31mAgentGenerationError: Error in generating model output:\u001b[0m\n",
       "\u001b[1;31mlitellm.BadRequestError: VolcengineException - The parameter `messages.content` specified in the request are not \u001b[0m\n",
       "\u001b[1;31mvalid: expected a string, but got `\u001b[0m\u001b[1;31m[\u001b[0m\u001b[1;31m{\u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m,\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"Thought: I will use the `web_search` tool to find out \u001b[0m\n",
       "\u001b[32mwho is the CEO of Hugging Face.\\nCode:\\n```py\\nceo_info = web_search\u001b[0m\u001b[32m(\u001b[0m\u001b[32mquery\u001b[0m\u001b[32m=\\\"Who is the CEO of Hugging \u001b[0m\n",
       "\u001b[32mFace?\\\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nprint\u001b[0m\u001b[32m(\u001b[0m\u001b[32mceo_info\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\u001b[0m\u001b[32m<\u001b[0m\u001b[32mend_code\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\"\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m,\u001b[0m\u001b[1;31m{\u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m,\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"Calling tools:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m'id': 'call_1', 'type': \u001b[0m\n",
       "\u001b[32m'function', 'function': \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'name': 'python_interpreter', 'arguments': 'ceo_info = web_search\u001b[0m\u001b[32m(\u001b[0m\u001b[32mquery\u001b[0m\u001b[32m=\\\"Who is the CEO \u001b[0m\n",
       "\u001b[32mof Hugging Face?\\\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\nprint\u001b[0m\u001b[32m(\u001b[0m\u001b[32mceo_info\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m]\u001b[0m\u001b[1;31m` instead. Request id: \u001b[0m\n",
       "\u001b[1;31m021742525541723d90807d1791e3f67b1750870f5bd8bf7225952\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 6.06 seconds| Input tokens: 2,416 | Output tokens: 57]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 6.06 seconds| Input tokens: 2,416 | Output tokens: 57]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating model output:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">litellm.BadRequestError: VolcengineException - The parameter `messages.content` specified in the request are not </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">valid: expected a string, but got `[{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">,</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Thought: I need to find out the CEO of Hugging Face. I </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">will use the `web_search_duck` tool to get this information.\\nCode:\\n```py\\nceo_info = web_search_duck(task=\\\"Find </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">out who is the CEO of Hugging Face.\\\")\\nprint(ceo_info)\\n```&lt;end_code&gt;\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">},{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">,</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">:</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Calling </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tools:\\n[{'id': 'call_1', 'type': 'function', 'function': {'name': 'python_interpreter', 'arguments': 'ceo_info = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">web_search_duck(task=\\\"Find out who is the CEO of Hugging Face.\\\")\\\\nprint(ceo_info)'}}\\]\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">}]` instead. Request id: </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">021742525541792d90807d1791e3f67b1750870f5bd8bf7b7b94e</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in generating model output:\u001b[0m\n",
       "\u001b[1;31mlitellm.BadRequestError: VolcengineException - The parameter `messages.content` specified in the request are not \u001b[0m\n",
       "\u001b[1;31mvalid: expected a string, but got `\u001b[0m\u001b[1;31m[\u001b[0m\u001b[1;31m{\u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m,\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"Thought: I need to find out the CEO of Hugging Face. I \u001b[0m\n",
       "\u001b[32mwill use the `web_search_duck` tool to get this information.\\nCode:\\n```py\\nceo_info = web_search_duck\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtask\u001b[0m\u001b[32m=\\\"Find \u001b[0m\n",
       "\u001b[32mout who is the CEO of Hugging Face.\\\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nprint\u001b[0m\u001b[32m(\u001b[0m\u001b[32mceo_info\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\u001b[0m\u001b[32m<\u001b[0m\u001b[32mend_code\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\"\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m,\u001b[0m\u001b[1;31m{\u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m,\u001b[0m\u001b[32m\"text\"\u001b[0m\u001b[1;31m:\u001b[0m\u001b[32m\"Calling \u001b[0m\n",
       "\u001b[32mtools:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m'id': 'call_1', 'type': 'function', 'function': \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'name': 'python_interpreter', 'arguments': 'ceo_info = \u001b[0m\n",
       "\u001b[32mweb_search_duck\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtask\u001b[0m\u001b[32m=\\\"Find out who is the CEO of Hugging Face.\\\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\nprint\u001b[0m\u001b[32m(\u001b[0m\u001b[32mceo_info\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m]\u001b[0m\u001b[1;31m` instead. Request id: \u001b[0m\n",
       "\u001b[1;31m021742525541792d90807d1791e3f67b1750870f5bd8bf7b7b94e\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 0.05 seconds| Input tokens: 4,832 | Output tokens: 114]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 0.05 seconds| Input tokens: 4,832 | Output tokens: 114]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AgentGenerationError",
     "evalue": "Error in generating model output:\nlitellm.BadRequestError: VolcengineException - The parameter `messages.content` specified in the request are not valid: expected a string, but got `[{\"type\":\"text\",\"text\":\"Thought: I need to find out the CEO of Hugging Face. I will use the `web_search_duck` tool to get this information.\\nCode:\\n```py\\nceo_info = web_search_duck(task=\\\"Find out who is the CEO of Hugging Face.\\\")\\nprint(ceo_info)\\n```<end_code>\"},{\"type\":\"text\",\"text\":\"Calling tools:\\n[{'id': 'call_1', 'type': 'function', 'function': {'name': 'python_interpreter', 'arguments': 'ceo_info = web_search_duck(task=\\\"Find out who is the CEO of Hugging Face.\\\")\\\\nprint(ceo_info)'}}]\"}]` instead. Request id: 021742525541792d90807d1791e3f67b1750870f5bd8bf7b7b94e",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\llms\\openai\\openai.py:727\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[1;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\llms\\openai\\openai.py:654\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[1;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[0;32m    642\u001b[0m logging_obj\u001b[38;5;241m.\u001b[39mpre_call(\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m    644\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mopenai_client\u001b[38;5;241m.\u001b[39mapi_key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    650\u001b[0m     },\n\u001b[0;32m    651\u001b[0m )\n\u001b[0;32m    653\u001b[0m headers, response \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_sync_openai_chat_completion_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopenai_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopenai_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m )\n\u001b[0;32m    662\u001b[0m logging_obj\u001b[38;5;241m.\u001b[39mmodel_call_details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m headers\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\litellm_core_utils\\logging_utils.py:149\u001b[0m, in \u001b[0;36mtrack_llm_api_timing.<locals>.decorator.<locals>.sync_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\llms\\openai\\openai.py:473\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.make_sync_openai_chat_completion_request\u001b[1;34m(self, openai_client, data, timeout, logging_obj)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\llms\\openai\\openai.py:455\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.make_sync_openai_chat_completion_request\u001b[1;34m(self, openai_client, data, timeout, logging_obj)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 455\u001b[0m     raw_response \u001b[38;5;241m=\u001b[39m openai_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mwith_raw_response\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    457\u001b[0m     )\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\openai\\_legacy_response.py:364\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[1;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    913\u001b[0m validate_response_format(response_format)\n\u001b[1;32m--> 914\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\openai\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1239\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m )\n\u001b[1;32m-> 1242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\openai\\_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\openai\\_base_client.py:1023\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1026\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1027\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1031\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1032\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'code': 'InvalidParameter', 'message': 'The parameter `messages.content` specified in the request are not valid: expected a string, but got `[{\"type\":\"text\",\"text\":\"Thought: I need to find out the CEO of Hugging Face. I will use the `web_search_duck` tool to get this information.\\\\nCode:\\\\n```py\\\\nceo_info = web_search_duck(task=\\\\\"Find out who is the CEO of Hugging Face.\\\\\")\\\\nprint(ceo_info)\\\\n```<end_code>\"},{\"type\":\"text\",\"text\":\"Calling tools:\\\\n[{\\'id\\': \\'call_1\\', \\'type\\': \\'function\\', \\'function\\': {\\'name\\': \\'python_interpreter\\', \\'arguments\\': \\'ceo_info = web_search_duck(task=\\\\\"Find out who is the CEO of Hugging Face.\\\\\")\\\\\\\\nprint(ceo_info)\\'}}]\"}]` instead. Request id: 021742525541792d90807d1791e3f67b1750870f5bd8bf7b7b94e', 'param': 'messages.content', 'type': 'BadRequest'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\main.py:1742\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[0m\n\u001b[0;32m   1736\u001b[0m     logging\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[0;32m   1737\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m   1738\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[0;32m   1739\u001b[0m         original_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m   1740\u001b[0m         additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: headers},\n\u001b[0;32m   1741\u001b[0m     )\n\u001b[1;32m-> 1742\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\main.py:1715\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1715\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_chat_completions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m   1729\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass AsyncOpenAI, OpenAI client\u001b[39;49;00m\n\u001b[0;32m   1731\u001b[0m \u001b[43m        \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\llms\\openai\\openai.py:738\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[1;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[0;32m    737\u001b[0m     error_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(error_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 738\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    739\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[0;32m    740\u001b[0m     message\u001b[38;5;241m=\u001b[39merror_text,\n\u001b[0;32m    741\u001b[0m     headers\u001b[38;5;241m=\u001b[39merror_headers,\n\u001b[0;32m    742\u001b[0m     body\u001b[38;5;241m=\u001b[39merror_body,\n\u001b[0;32m    743\u001b[0m )\n",
      "\u001b[1;31mOpenAIError\u001b[0m: Error code: 400 - {'error': {'code': 'InvalidParameter', 'message': 'The parameter `messages.content` specified in the request are not valid: expected a string, but got `[{\"type\":\"text\",\"text\":\"Thought: I need to find out the CEO of Hugging Face. I will use the `web_search_duck` tool to get this information.\\\\nCode:\\\\n```py\\\\nceo_info = web_search_duck(task=\\\\\"Find out who is the CEO of Hugging Face.\\\\\")\\\\nprint(ceo_info)\\\\n```<end_code>\"},{\"type\":\"text\",\"text\":\"Calling tools:\\\\n[{\\'id\\': \\'call_1\\', \\'type\\': \\'function\\', \\'function\\': {\\'name\\': \\'python_interpreter\\', \\'arguments\\': \\'ceo_info = web_search_duck(task=\\\\\"Find out who is the CEO of Hugging Face.\\\\\")\\\\\\\\nprint(ceo_info)\\'}}]\"}]` instead. Request id: 021742525541792d90807d1791e3f67b1750870f5bd8bf7b7b94e', 'param': 'messages.content', 'type': 'BadRequest'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\smolagents\\agents.py:1186\u001b[0m, in \u001b[0;36mCodeAgent.step\u001b[1;34m(self, memory_step)\u001b[0m\n\u001b[0;32m   1185\u001b[0m additional_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrammar\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrammar} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrammar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1186\u001b[0m chat_message: ChatMessage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_messages,\n\u001b[0;32m   1188\u001b[0m     stop_sequences\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<end_code>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObservation:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling tools:\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madditional_args,\n\u001b[0;32m   1190\u001b[0m )\n\u001b[0;32m   1191\u001b[0m memory_step\u001b[38;5;241m.\u001b[39mmodel_output_message \u001b[38;5;241m=\u001b[39m chat_message\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\smolagents\\models.py:904\u001b[0m, in \u001b[0;36mLiteLLMModel.__call__\u001b[1;34m(self, messages, stop_sequences, grammar, tools_to_call_from, **kwargs)\u001b[0m\n\u001b[0;32m    891\u001b[0m completion_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_completion_kwargs(\n\u001b[0;32m    892\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m    893\u001b[0m     stop_sequences\u001b[38;5;241m=\u001b[39mstop_sequences,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    902\u001b[0m )\n\u001b[1;32m--> 904\u001b[0m response \u001b[38;5;241m=\u001b[39m litellm\u001b[38;5;241m.\u001b[39mcompletion(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompletion_kwargs)\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_input_token_count \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39musage\u001b[38;5;241m.\u001b[39mprompt_tokens\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\utils.py:1235\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1232\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[0;32m   1233\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[0;32m   1234\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[1;32m-> 1235\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\utils.py:1113\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[1;32m-> 1113\u001b[0m result \u001b[38;5;241m=\u001b[39m original_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1114\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\main.py:3137\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[0m\n\u001b[0;32m   3135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3136\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[1;32m-> 3137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:2214\u001b[0m, in \u001b[0;36mexception_type\u001b[1;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[0;32m   2213\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[1;32m-> 2214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   2215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:384\u001b[0m, in \u001b[0;36mexception_type\u001b[1;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n\u001b[0;32m    385\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    386\u001b[0m         llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[0;32m    387\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    388\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    389\u001b[0m         litellm_debug_info\u001b[38;5;241m=\u001b[39mextra_information,\n\u001b[0;32m    390\u001b[0m     )\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m original_exception\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n",
      "\u001b[1;31mBadRequestError\u001b[0m: litellm.BadRequestError: VolcengineException - The parameter `messages.content` specified in the request are not valid: expected a string, but got `[{\"type\":\"text\",\"text\":\"Thought: I need to find out the CEO of Hugging Face. I will use the `web_search_duck` tool to get this information.\\nCode:\\n```py\\nceo_info = web_search_duck(task=\\\"Find out who is the CEO of Hugging Face.\\\")\\nprint(ceo_info)\\n```<end_code>\"},{\"type\":\"text\",\"text\":\"Calling tools:\\n[{'id': 'call_1', 'type': 'function', 'function': {'name': 'python_interpreter', 'arguments': 'ceo_info = web_search_duck(task=\\\"Find out who is the CEO of Hugging Face.\\\")\\\\nprint(ceo_info)'}}]\"}]` instead. Request id: 021742525541792d90807d1791e3f67b1750870f5bd8bf7b7b94e",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAgentGenerationError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 14\u001b[0m\n\u001b[0;32m      3\u001b[0m web_agent \u001b[38;5;241m=\u001b[39m CodeAgent(\n\u001b[0;32m      4\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[DuckDuckGoSearchTool()],\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      6\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_duck\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRuns web searches for you. Give it your query as an argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m manager_agent \u001b[38;5;241m=\u001b[39m CodeAgent(\n\u001b[0;32m     11\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[], model\u001b[38;5;241m=\u001b[39mmodel, managed_agents\u001b[38;5;241m=\u001b[39m[web_agent]\n\u001b[0;32m     12\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmanager_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWho is the CEO of Hugging Face?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\smolagents\\agents.py:323\u001b[0m, in \u001b[0;36mMultiStepAgent.run\u001b[1;34m(self, task, stream, reset, images, additional_args, max_steps)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask, max_steps\u001b[38;5;241m=\u001b[39mmax_steps, images\u001b[38;5;241m=\u001b[39mimages)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# Outputs are returned only at the end. We only look at the last step.\u001b[39;00m\n\u001b[1;32m--> 323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeque\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\smolagents\\agents.py:337\u001b[0m, in \u001b[0;36mMultiStepAgent._run\u001b[1;34m(self, task, max_steps, images)\u001b[0m\n\u001b[0;32m    334\u001b[0m     final_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_step(task, memory_step)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AgentGenerationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m# Agent generation errors are not caused by a Model error but an implementation error: so we should raise them and exit.\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AgentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;66;03m# Other AgentError types are caused by the Model, so we should log them and iterate.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m     memory_step\u001b[38;5;241m.\u001b[39merror \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\smolagents\\agents.py:334\u001b[0m, in \u001b[0;36mMultiStepAgent._run\u001b[1;34m(self, task, max_steps, images)\u001b[0m\n\u001b[0;32m    332\u001b[0m memory_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_memory_step(step_start_time, images)\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 334\u001b[0m     final_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AgentGenerationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m# Agent generation errors are not caused by a Model error but an implementation error: so we should raise them and exit.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\smolagents\\agents.py:358\u001b[0m, in \u001b[0;36mMultiStepAgent._execute_step\u001b[1;34m(self, task, memory_step)\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplanning_step(task, is_first_step\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m), step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_rule(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, level\u001b[38;5;241m=\u001b[39mLogLevel\u001b[38;5;241m.\u001b[39mINFO)\n\u001b[1;32m--> 358\u001b[0m final_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_answer_checks:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_final_answer(final_answer)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\airsim_agent\\lib\\site-packages\\smolagents\\agents.py:1202\u001b[0m, in \u001b[0;36mCodeAgent.step\u001b[1;34m(self, memory_step)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     memory_step\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m=\u001b[39m model_output\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AgentGenerationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in generating model output:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_markdown(\n\u001b[0;32m   1205\u001b[0m     content\u001b[38;5;241m=\u001b[39mmodel_output,\n\u001b[0;32m   1206\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput message of the LLM:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1207\u001b[0m     level\u001b[38;5;241m=\u001b[39mLogLevel\u001b[38;5;241m.\u001b[39mDEBUG,\n\u001b[0;32m   1208\u001b[0m )\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;66;03m# Parse\u001b[39;00m\n",
      "\u001b[1;31mAgentGenerationError\u001b[0m: Error in generating model output:\nlitellm.BadRequestError: VolcengineException - The parameter `messages.content` specified in the request are not valid: expected a string, but got `[{\"type\":\"text\",\"text\":\"Thought: I need to find out the CEO of Hugging Face. I will use the `web_search_duck` tool to get this information.\\nCode:\\n```py\\nceo_info = web_search_duck(task=\\\"Find out who is the CEO of Hugging Face.\\\")\\nprint(ceo_info)\\n```<end_code>\"},{\"type\":\"text\",\"text\":\"Calling tools:\\n[{'id': 'call_1', 'type': 'function', 'function': {'name': 'python_interpreter', 'arguments': 'ceo_info = web_search_duck(task=\\\"Find out who is the CEO of Hugging Face.\\\")\\\\nprint(ceo_info)'}}]\"}]` instead. Request id: 021742525541792d90807d1791e3f67b1750870f5bd8bf7b7b94e"
     ]
    }
   ],
   "source": [
    "from smolagents import CodeAgent, HfApiModel, DuckDuckGoSearchTool\n",
    "\n",
    "web_agent = CodeAgent(\n",
    "    tools=[DuckDuckGoSearchTool()],\n",
    "    model=model,\n",
    "    name=\"web_search_duck\",\n",
    "    description=\"Runs web searches for you. Give it your query as an argument.\"\n",
    ")\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    tools=[], model=model, managed_agents=[web_agent]\n",
    ")\n",
    "\n",
    "manager_agent.run(\"Who is the CEO of Hugging Face?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6717c87-b8cb-451d-af93-f171ed9da524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
